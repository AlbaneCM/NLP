{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d4037f",
   "metadata": {},
   "source": [
    "# Natural Language Processing: Tweet Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a2e48",
   "metadata": {},
   "source": [
    "**Author**: Albane Colmenares <br>\n",
    "**Date**: December 12th, 2023 <br>\n",
    "___________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e25ce2",
   "metadata": {},
   "source": [
    "### Table of Content\n",
    "**1. [Overview](#overview)**<br>\n",
    "**2. [Business Understanding](#business_understanding)**<br>\n",
    "**3. [Data Understanding](#data_understanding)**<br>\n",
    "**4. [Data Preparation](#data_preparation)**<br>\n",
    "**5. [Modeling](#modeling)**<br>\n",
    "**6. [Evaluation](#evaluation)**<br>\n",
    "**7. [Findings & Recommendations](#findings_n_recommendations)**<br>\n",
    "**8. [Limits & Next Steps](#limits_n_next_steps)**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59435e3d",
   "metadata": {},
   "source": [
    "overview\n",
    "<a id='overview'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7bc745",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88bbf7",
   "metadata": {},
   "source": [
    "This notebook examines tweets about Google and Apple products and predicts whether the sentiment of unseen tweets is positive or negative. <br>\n",
    "The organization of this notebook follows the CRoss Industry Standard Process for Data Mining (CRISP-DM) is a process model that serves as the base for a data science process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017c15fd",
   "metadata": {},
   "source": [
    "business_understanding\n",
    "<a id='business_understanding'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc41608",
   "metadata": {},
   "source": [
    "## 2. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc38a169",
   "metadata": {},
   "source": [
    "We, as the agency entrusted by Samsung, have been tasked with shaping the marketing strategy for the imminent <u>launch</u> of their cutting-edge <u>folding tablet</u>. \n",
    "<br>Due to the unique nature of the product, substantial funds were allocated for research and development. Consequently, there is a constraint on budget for the launch phase. \n",
    "<br>Nevertheless, Samsung aims to generate significant buzz around this groundbreaking product, confident that its innovation will speak for itself. \n",
    "\n",
    "\n",
    "In our initial conversations, it was recommened that the product be unveiled at South by Southwest, a major conference in the industry. The event has an `Interactive` division, which focuses on new technology where speakers, parties and trade shows are hosted. \n",
    "\n",
    "The objective of this project has two main aspects: \n",
    "1. Analyze the success stories of the two technology leaders in the industry at South by Southwest \n",
    "    * Identify factors that were received positively to understand dynamics of a successful launch - and not positive responses to know what to avoid\n",
    "2. Predict the tweets' sentiment \n",
    "    * Every strategy needs to measure the Return On Investment. Predicting tweet sentiment will provide a quantifiable metric to evaluate the efficacy of the deployed strategy.\n",
    "    \n",
    "    \n",
    "The target audience is Samsung marketing strategy teams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146535ef",
   "metadata": {},
   "source": [
    "data_understanding\n",
    "<a id='data_understanding'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0faaa",
   "metadata": {},
   "source": [
    "## 3. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8bc5af",
   "metadata": {},
   "source": [
    "* **Data Source**\n",
    "\n",
    "The data comes from CrowdFlower via [data.world](https://data.world/crowdflower/brands-and-product-emotions). \n",
    "\n",
    "Tweets about the two leading technology brands and products were grouped into the dataset. The tweets were categorized by the sentiment that was expressed: positive, negative or neutral. The product or brand referenced by the short text is also indicated when known. \n",
    "\n",
    "The file `judge-1377884607_tweet_product_company.csv` can be downloaded at the provided link. \n",
    "It was then renamed to `tweet_product_company.csv`and saved into the current folder, within the 'data' subfolder, to be accessed into the raw DataFrame. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e546fea",
   "metadata": {},
   "source": [
    "* **Features**\n",
    "\n",
    "Prior to preprocessing, the columns are: \n",
    "\n",
    "* `tweet_text`: the actual tweet's record\n",
    "* `emotion_in_tweet_is_directed_at`: the product or company referred to in the tweet\n",
    "* `is_there_an_emotion_directed_at_a_brand_or_product`: the tweet's sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402a218",
   "metadata": {},
   "source": [
    "* **Target**\n",
    "\n",
    "The tweet's sentiment is the target for the dataset. The specific column is `is_there_an_emotion_directed_at_a_brand_or_product`. Based on a given set of tweets, we will try to predict if the tweet's emotion was positive, negative or neutral. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7405f",
   "metadata": {},
   "source": [
    "* **Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87b4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d550d",
   "metadata": {},
   "source": [
    "The text file is encoded using Latin-1 encoding - and is open as is. Several encodings were tried to ensure the right one matched: utf-8, utf-16, ascii for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3fa494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset and saving it as raw_df\n",
    "raw_df = pd.read_csv('data/tweet_product_company.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d847e810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the first 5 rows of the DataFrame\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b15678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 9093 rows and 3 columns.\n"
     ]
    }
   ],
   "source": [
    "# Printing the number of rows and columns in the dataset\n",
    "print(f'The dataset has '+ str(len(raw_df)) + ' rows and 3 columns.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12216ee6",
   "metadata": {},
   "source": [
    "The various companies and products referred to in the tweets will be reviewed to get an understand of the balance in the dataset, along with what is being most often reviewed.  \n",
    "\n",
    "Similarly, the emotions will be reviewed in a similar way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f4e4c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the number of tweets referring to each product or company\n",
    "raw_df['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe7717",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspecting the number of tweets referring to each emotion\n",
    "raw_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc2d907",
   "metadata": {},
   "source": [
    "data_preparation\n",
    "<a id='data_preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fbb6ec",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071ec4c",
   "metadata": {},
   "source": [
    "## 4: 1- <u>Data Cleaning</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b857f",
   "metadata": {},
   "source": [
    "For a better readability of the tweets' texts, the column width will be increased. In addition, the use of MathJax will be disabled so that the visual representation of mathematical expressions are not displayed so this doesn't cause issues to the environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing column width\n",
    "pd.set_option('max_colwidth', 400)\n",
    "pd.set_option('use_mathjax', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784b844",
   "metadata": {},
   "source": [
    "### 4. a) Column names' change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3497778",
   "metadata": {},
   "source": [
    "The column names are particularly long. For an easier process to handle, they will be renamed in the new DataFrame called `df`:\n",
    "* `tweet`\n",
    "* `product_or_company`\n",
    "* `sentiment`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the raw DataFrame to modify it\n",
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the new columns' names and attributing them to the new DataFrame\n",
    "df.columns = ['tweet', 'product_or_company', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac7e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verifying the changes applied  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d20cc",
   "metadata": {},
   "source": [
    "### 4. c) Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7c57da",
   "metadata": {},
   "source": [
    "In the next section, the missing values are inspected and handled by category. \n",
    "<br>\n",
    "The `tweet` column only had 1 row with null values and had no implication on other features: it is removed. \n",
    "<br>\n",
    "The `product_or_company` requires contains many more missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4490695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looking for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897d890",
   "metadata": {},
   "source": [
    "* **Tweet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1008ea2",
   "metadata": {},
   "source": [
    "The tweet column only has one null value with no information on the other columns: it will be dropped from the DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe1f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspecting the tweet containing null information \n",
    "df[df['tweet'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c51618",
   "metadata": {},
   "source": [
    "The null tweet does not contain any information for either column and will be dropped.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be3a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the null tweet from the DataFrame\n",
    "df = df.dropna(subset=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1401ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verifying it was correctly removed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b70ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the new length of the dataset\n",
    "print(f'The dataset now has '+ str(len(df)) + '. The missing tweet was removed.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e13bd",
   "metadata": {},
   "source": [
    "* **Product or Company**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acca6ca",
   "metadata": {},
   "source": [
    "The product_or_company column contains many null values where neither the product or the brand was specified. For now, all null values will be replaced by 'unknown', as the focus is to predict sentiment. \n",
    "<br>If the focus on product or company needs to be done, two columns will be created to identify the product and the brand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a894c971",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspecting the tweet containing null information \n",
    "df[df['product_or_company'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the null product or company with 'undefined'\n",
    "df['product_or_company'] = df['product_or_company'].fillna('undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222f880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verifying it was correctly handled\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ec998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the new length of the dataset\n",
    "print(f'The dataset still has '+ str(len(df)) + '.' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed26587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verifying the count of rows by unique value in this column\n",
    "df['product_or_company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288a677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verifying the count of rows by unique value in this column\n",
    "df['product_or_company'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfb9ad",
   "metadata": {},
   "source": [
    "### 4. d) Handling duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows were duplicates\n",
    "print(str(len(df[df.duplicated()])) + f' duplicate rows were identified.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fdb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the duplicate rows\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying with one example that tweets were indeed duplicated \n",
    "df[df['tweet'] == 'Before It Even Begins, Apple Wins #SXSW {link}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a598d6",
   "metadata": {},
   "source": [
    "### 4. d) Turning sentiment classification into a binary one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328881f",
   "metadata": {},
   "source": [
    "* **Product or Company**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37b1f74",
   "metadata": {},
   "source": [
    "The product or company column does not have an impact on whether a tweet is positive or negative, so it will not be transformed as it will not be used further for predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70baaac",
   "metadata": {},
   "source": [
    "* **Sentiment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee879e",
   "metadata": {},
   "source": [
    "Four sentiment categories are described, which could be grouped in two: positive and not positive. \n",
    "<br>This is what will be covered over the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0163c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows by emotion\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533c0b3",
   "metadata": {},
   "source": [
    "* **Categorizing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790dc9b",
   "metadata": {},
   "source": [
    "Due to the nature of the target, we will focus on the positive ones. Hence all the other tweets, whether they are neutral or negative, will be considered ***not positive***. For easier reference, it will be identified as ***negative***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e361457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the new classifications for the sentiment column \n",
    "classification_columns = {\n",
    "    'sentiment': {\n",
    "        \"No emotion toward brand or product\": \"negative\", \n",
    "        \"I can't tell\": \"negative\", \n",
    "        \"Positive emotion\": \"positive\", \n",
    "        \"Negative emotion\": \"negative\" \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb48b03",
   "metadata": {},
   "source": [
    "We will now convert the sentiment column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e19d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the sentiment column classification\n",
    "\n",
    "# Defining columns to change\n",
    "column_classification = ['sentiment']\n",
    "\n",
    "def convert_class(df, columns_mapping):\n",
    "    for column, mapping in columns_mapping.items():\n",
    "        print('Before: ' + column, df[column].unique())\n",
    "        df[column] = df[column].map(mapping)\n",
    "        print('After: ' + column, df[column].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2cfc7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling the function to convert the classification into a binary one\n",
    "convert_class(df, classification_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewiewing the new categorization of rows by unique sentiment\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar chart for to visualize class imbalance\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# Defining custom colors \n",
    "custom_colors = ['#3B3935', '#00917C']\n",
    "\n",
    "sns.countplot(data=df, x='sentiment', order=df['sentiment'].value_counts().index, palette=custom_colors)\n",
    "\n",
    "ax.set_xlabel(xlabel = 'Sentiment', fontsize=15)\n",
    "ax.set_ylabel(ylabel = 'Number of Tweets', fontsize=15)\n",
    "\n",
    "ax.set_xticklabels(labels=['Negative', 'Positive'])\n",
    "\n",
    "ax.set_title(f'Number of Tweets per Sentiment')\n",
    "\n",
    " # Saving the plot as a PNG with a transparent background\n",
    "plt.savefig('images/tweets_per_sentiment.png', transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc6807",
   "metadata": {},
   "source": [
    "### 4. e) Performing a Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ee8d7",
   "metadata": {},
   "source": [
    "The dataset is being divided into two separate subsets: a training set, and a testing (or validation) set. The validation set will allow to assess the performance of the model.\n",
    "\n",
    "Two parameters are assigned when dividing the dataset:\n",
    "* random_state=42\n",
    "    * setting a random seed of 42 ensures that the data split is reproducible\n",
    "* stratify=y\n",
    "    * stratified sampling ensures the class distribution is maintained in both sets to address potential class imbalance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b7a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting df into X and y\n",
    "X = df.drop('sentiment', axis=1)\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the X_train data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the y_train data \n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7863e",
   "metadata": {},
   "source": [
    "* **Distribution of Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the values of sentiment categories   \n",
    "train_target_counts = pd.DataFrame(y_train.value_counts())\n",
    "train_target_counts.index.name = 'target name'\n",
    "train_target_counts.rename(columns={'sentiment': 'count'}, inplace=True)\n",
    "\n",
    "# Inspecting the grouped results\n",
    "train_target_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92d494",
   "metadata": {},
   "source": [
    "* **Visually Inspecting Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee42837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making a sample of 5 records to display the full text of each\n",
    "train_sample = X_train.sample(5, random_state=22)\n",
    "train_sample['label'] = [y_train[val] for val in train_sample.index]\n",
    "train_sample.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e3ac6",
   "metadata": {},
   "source": [
    "## 4: 2- <u>Data Preprocessing & Exploratory Analysis</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb1807",
   "metadata": {},
   "source": [
    "In order to preprocess the tweets, the following transformations were performed: \n",
    "* **Standardizing case**\n",
    "    <br>This step is important to ensure text is uniform and consistent. This prevents models from treating words with different cases as different ones\n",
    "    \n",
    "* **Tokenizing**\n",
    "    <br>Tokens of one or two consecutive words were created. This was done with the `RegexpTokenizer` package from nltk.tokenize <br>\n",
    "* **Stopwords** \n",
    "    <br>To focus on the data's theme, English stopwords were removed. Manual additions were made in this text's context (i.e. \"sxsw\", \"mention\")  \n",
    "* **Lemmatize** \n",
    "    <br> The `WordNetLemmatizer` package from nltk.stem.wordnet was used to reduce words to their base form, allowing a more accurate analysis\n",
    "* **Frequency Distribution**\n",
    "    <br>The `FreqDist` package was used to review in a dictionary-like output, the words and their frequencies\n",
    "* **WordCloud**\n",
    "    <br> The words' frequencies were represented visually thanks to the `WordCloud` package\n",
    "* **Bigrams**\n",
    "    <br> Bigrams were drawn to have a better understanding of the themes, i.e. pop was identified with pop-up store, thanks to the `collocations` package and its BigramAssocMeasures\n",
    "* **Mutual Information Scores**\n",
    "    <br> Bigrams that occur more than 5 times were examined through `mutual information scores`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7274ed3",
   "metadata": {},
   "source": [
    "Before any transformation is done, a copy of the tweet column will be done so the original one can always be accessed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating the column tweet\n",
    "X_train['tweet_original'] = X_train['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the new column was correctly created\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140b937",
   "metadata": {},
   "source": [
    "### 4: 2- a) Standardizing Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee9777a",
   "metadata": {},
   "source": [
    "We will glance at the first sample of tweet to get an idea of whether we need to standardize case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating the first tweet into windows_sample\n",
    "tweet_sample = train_sample.iloc[0][\"tweet\"]\n",
    "tweet_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f8f99e",
   "metadata": {},
   "source": [
    "* **Lower case**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a3d9c",
   "metadata": {},
   "source": [
    "Changing to lower case is necessary. We will apply this to the first tweet sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming sample data to lowercase\n",
    "tweet_sample.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe71430",
   "metadata": {},
   "source": [
    "This answers our needs - we will apply this to our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dae3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming sample data to lowercase\n",
    "train_sample['tweet'] = train_sample['tweet'].str.lower()\n",
    "# Displaying full text\n",
    "train_sample.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492fe78",
   "metadata": {},
   "source": [
    "This answers our needs - we will apply this to our full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc305a",
   "metadata": {},
   "source": [
    "### 4: 2- b) Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab50da4",
   "metadata": {},
   "source": [
    "The second fundamental data cleaning step is to tokenize the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing one of our train_sample tweets\n",
    "tweet_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c308e",
   "metadata": {},
   "source": [
    "We will use `RegexpTokenizer` from NLTK to create tokens of tow or more consecutive word characters, which include letters, numbers and underscores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aefe0d",
   "metadata": {},
   "source": [
    "* **Tokenizing Pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922db24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing RegexpTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "\n",
    "# Instantiating the tokenizer\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)\n",
    "\n",
    "# Tokenizing the tweets\n",
    "tweet_tokenized = tokenizer.tokenize(tweet_sample)\n",
    "tweet_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f979e84",
   "metadata": {},
   "source": [
    "We will now apply it to our full sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b3c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying the tokenizer on the full train sample\n",
    "train_sample['tweet'] = train_sample['tweet'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7055ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting it\n",
    "train_sample['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874a30b",
   "metadata": {},
   "source": [
    "### 4: 2- c) Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0566b090",
   "metadata": {},
   "source": [
    "Then, we will be removing stopwords so we can focus on the the text data's theme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e9e9a",
   "metadata": {},
   "source": [
    "Typical list of stopwords to which we will add:\n",
    "* `sxsw`: the name of the conference \n",
    "* `mention`: when tweeted\n",
    "* `link`: ?\n",
    "* `RT`: retweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108de336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Creating list to store stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767223e",
   "metadata": {},
   "source": [
    "Some words are manually added to the list of stopwords, as they are in reference with tweets only. For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ff1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing words to add to list of stopwords\n",
    "manual_stopwords = ['sxsw', 'mention', 'link', 'rt']\n",
    "\n",
    "# Adding to list of stopwords\n",
    "for word in manual_stopwords:\n",
    "    stopwords_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the new words were added\n",
    "stopwords_list[-len(manual_stopwords):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89619dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function that takes in a list of strings and returns only those that are not in the list\n",
    "def remove_stopwords(token_list, stopwords_list):\n",
    "    stopwords_removed = [token for token in token_list if token not in stopwords_list]\n",
    "    return stopwords_removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90852828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing it on an example\n",
    "tokens_example = train_sample.iloc[0]['tweet']\n",
    "print(\"Length with stopwords: \", len(tokens_example))\n",
    "\n",
    "tokens_example_without_stopwords = remove_stopwords(tokens_example, stopwords_list)\n",
    "print(\"Length with stopwords: \", len(tokens_example_without_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0f70a",
   "metadata": {},
   "source": [
    "### 4: 2- d) Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a68327",
   "metadata": {},
   "source": [
    "The WordNetLemmatizer package from nltk.stem.wordnet was used to reduce words to their base form, allowing a more accurate analysis. \n",
    "<br>It first required to be downloaded for Jupyter Notebook. Once the initial download is done, this step was commented out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ff2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant package\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "# Instantiating the Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Lemmatizer\n",
    "def lemmatize_words(token_list):\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos='v') for token in token_list]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cef8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now apply it to our full sample\n",
    "# Applying the lemmatize function to our full dataset \n",
    "# lemmatize_words(train_sample['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ad6cc",
   "metadata": {},
   "source": [
    "### 4: 2- e) Tweet Preprocessing Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cdd6fd",
   "metadata": {},
   "source": [
    "The previous steps will be summarized in a function so the above steps can be applied to the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca473616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring the relevant packages are imported\n",
    "# These were imported individually before but are reminded here if they needed to be used solely for the function\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# nltk.download('stopwords', quiet=True)\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95588860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function\n",
    "def tweet_preprocess(text):\n",
    "    # 1. Standardizing case\n",
    "    text = text.lower()  \n",
    "    \n",
    "    \n",
    "    # 2. Tokenizing\n",
    "    # Defining the token pattern\n",
    "    token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "    # Instantiating the tokenizer \n",
    "    tokenizer = RegexpTokenizer(token_pattern)\n",
    "    # Tokenizing\n",
    "    text = tokenizer.tokenize(text)\n",
    "    \n",
    "    # 3. Stopwords\n",
    "    # Creating list to store stopwords\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    \n",
    "    # Storing words to add to list of stopwords\n",
    "    manual_stopwords = ['sxsw', 'sxswi', 'mention', 'link', 'rt', 'amp', 'www', 'com', 'quot']\n",
    "    # Adding to list of stopwords\n",
    "    for word in manual_stopwords:\n",
    "        stopwords_list.append(word)\n",
    "    \n",
    "    # Removing stopwords \n",
    "    text = [token for token in text if token not in stopwords_list]\n",
    "    \n",
    "    \n",
    "    # 4. Lemmatizing\n",
    "    # Instantiating the Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Lemmatizing words \n",
    "    text = [lemmatizer.lemmatize(token) for token in text]\n",
    "    \n",
    "    #Returning the preprocessed tweet\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our function on one tweet\n",
    "tweet_preprocess(X_train['tweet'].iloc[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying this to our whole dataset\n",
    "X_train['tweet'] = X_train['tweet'].apply(lambda x: tweet_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44954f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating a column with of preprocessed tweets without being stored in lists\n",
    "X_train['tokenized_tweet'] = X_train['tweet'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26890ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the newly created column\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e540f63",
   "metadata": {},
   "source": [
    "* **Preprocessing test data for later use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e6010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a duplicate of the tweet column \n",
    "X_test['tweet_original'] = X_test['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing tweets to the test data\n",
    "X_test['tweet'] = X_test['tweet'].apply(lambda x: tweet_preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e8a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating a column of preprocessed tweets without being stored in lists, for the test data too\n",
    "X_test['tokenized_tweet'] = X_test['tweet'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c627d",
   "metadata": {},
   "source": [
    "### 4: 2- f) Frequency Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b076ab",
   "metadata": {},
   "source": [
    "A frequency distribution is a data structure which can be compared to a list displaying how often a piece of data - or a word appears. \n",
    "\n",
    "In order to do this, we will use the `FreqDist` package. It allows us to pass in a single list of words. It then produces a dictionary-like output of those words and their frequencies.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce13a95f",
   "metadata": {},
   "source": [
    "We will visualize the top 10 words to evaluate further what cleaning needs to be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant package: FreqDist\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e68c3",
   "metadata": {},
   "source": [
    "* **FreqDist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f47008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an example of Frequency distribution for 1 tweet\n",
    "example_freq_dist = FreqDist(X_train.iloc[100]['tweet'][:20])\n",
    "example_freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant package for top number of words\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Creating a function to visualize the top 10 words\n",
    "\n",
    "def visualize_top_10(freq_dist, title):\n",
    "#     extracting data for graph\n",
    "    top_10 = list(zip(*freq_dist.most_common(10)))\n",
    "    tokens = top_10[0]\n",
    "    counts = top_10[1]\n",
    "    \n",
    "#     Setting up graph and plotting data\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(tokens, counts, color='#3F3533')\n",
    "    ax.set_facecolor('#F5F2EE')\n",
    "#     Custominzing plot appearance \n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    \n",
    "visualize_top_10(example_freq_dist, \"Top 10 Word Frequency for Example Tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b2c4e",
   "metadata": {},
   "source": [
    "* **FreqDist on the Full DataSet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614121d1",
   "metadata": {},
   "source": [
    "In order to calculate the count of words, they need to be stored into a list. To do so, we will `explode` the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8269410",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a frequency distribution for X_train\n",
    "train_freq_dist = FreqDist(X_train['tweet'].explode())\n",
    "\n",
    "# Plotting the top 10 tokens\n",
    "visualize_top_10(train_freq_dist, 'Top 10 Word Frequency for Full X_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the most common 20 words\n",
    "train_freq_dist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5eb279",
   "metadata": {},
   "source": [
    "We will also subdivide this by category (positive/negative) to see if it makes a difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding in labels for filtering\n",
    "X_train['label'] = [y_train[val] for val in X_train.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining customer colors\n",
    "custom_colors = ['#3F3533', '#F5F2EE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8b67e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining funcrion to plot 2 visualizations\n",
    "\n",
    "# Creating two columns \n",
    "def two_subplits():\n",
    "    fig = plt.figure(figsize=(15, 9))\n",
    "    fig.set_tight_layout(True)\n",
    "    gs = fig.add_gridspec(1, 2)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0]) #row 0, col 0 \n",
    "    ax2 = fig.add_subplot(gs[0, 1]) #row 0, col 1 \n",
    "    return fig, [ax1, ax2]\n",
    "\n",
    "# Plotting the graph\n",
    "def plot_distribution_by_sentiment(X_version, column, axes, title = \"Word Frequency for:\"):\n",
    "    for index, category in enumerate(X_version['label'].unique()): \n",
    "#         Calculating frequency distribution for this subset\n",
    "        all_words = X_version[X_version['label'] == category][column].explode()\n",
    "        freq_dist = FreqDist(all_words)\n",
    "        top_10 = list(zip(*freq_dist.most_common(10)))\n",
    "        tokens = top_10[0]\n",
    "        counts = top_10[1]\n",
    "        \n",
    "        \n",
    "#         Setting up a plot\n",
    "        ax = axes[index]\n",
    "        ax.bar(tokens, counts, color='#3F3533')\n",
    "        \n",
    "#         Setting background color\n",
    "        ax.set_facecolor('#F5F2EE')\n",
    "    \n",
    "#         Customizing plot appearance\n",
    "        ax.set_title(f\"{title} {category}\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    " \n",
    "         \n",
    "fig, axes = two_subplits()\n",
    "plot_distribution_by_sentiment(X_train, 'tweet', axes)\n",
    "fig.suptitle('Word Frequencies for Each Sentiment', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8230cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency distribution\n",
    "# Defining subset prior. Here: positive, negative, no company tweets\n",
    "\n",
    "negative_tweets = X_train[X_train['label'] == 'negative']\n",
    "positive_tweets = X_train[X_train['label'] == 'positive']\n",
    "no_product_or_company = X_train[X_train['product_or_company'] == 'undefined']\n",
    "\n",
    "def freq_distr(subset, most_common):\n",
    "    exploded_subset = subset['tweet'].explode()\n",
    "    subset_freq = FreqDist(exploded_subset)\n",
    "    return subset_freq.most_common(most_common)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting frequency distribution for top 20 strings of no_product_or_company\n",
    "freq_distr(no_product_or_company, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68db1f29",
   "metadata": {},
   "source": [
    "### 4: 2- g) WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b594b",
   "metadata": {},
   "source": [
    "We will now visually represent the most frequently mentioned words, without representing them in a bar graph. \n",
    "<br>Word clouds visually represent the frequency of words in a given text, with more frequently occurring words displayed in larger font size. This allows a quick and intuitive overview of the words occuring most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing wordcloud\n",
    "# !pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host=files.pythonhosted.org wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Defining a colormap that interpolates between the two defined colors\n",
    "custom_colors = ['#3F3533', '#F5F2EE']\n",
    "\n",
    "n_bins = 5 \n",
    "\n",
    "# Creating the custom colormap\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", custom_colors, N=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb7c9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing relevant packages \n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Concatenate all tweets into a single string\n",
    "all_tweets = ' '.join(X_train['tweet'].apply(lambda x: ' '.join(map(str, x))))\n",
    "\n",
    "# Defining the function to plot wordclouds\n",
    "def wordcloud_graph(text):\n",
    "    \n",
    "    # Generate a word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='#F5F2EE', colormap=custom_cmap).generate(all_tweets)\n",
    "\n",
    "    # Display the generated word cloud using matplotlib\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00ad58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calling the function on all tweets\n",
    "wordcloud_graph(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell only is used for the purpose of searching words through the tweets \n",
    "word_researched = 'quot'\n",
    "filtered_on_word = X_train[X_train['tweet'].apply(lambda tweet_list: any(word_researched in s for s in tweet_list))]\n",
    "# filtered_on_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75cc22",
   "metadata": {},
   "source": [
    "Whether it comes from the frequency distribution or word cloud, the product and companies are the words that come up the most. 64% of the data does not contain any company or product. We will try filtering on this one to understand if the top words are different.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5033663d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verifying the count of rows by unique value in this column\n",
    "df['product_or_company'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bf81f",
   "metadata": {},
   "source": [
    "* **No company**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fbe67b",
   "metadata": {},
   "source": [
    "Let's inspect the dataframe filtered only on the ones where no product or company was included to review if there are any distinctions in the most frequent words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122501a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame for undefined product or company\n",
    "no_company = X_train[X_train['product_or_company'] == 'undefined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1052ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all tweets into a single string\n",
    "no_company_tweets = ' '.join(no_company['tweet'].apply(lambda x: ' '.join(map(str, x))))\n",
    "\n",
    "# Drawing the wordcloud on the list including only 'undefined' companies or products\n",
    "wordcloud_graph(no_company_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679317f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the frequency for each sentiment - only of 'undefined' products or companies \n",
    "fig, axes = two_subplits()\n",
    "plot_distribution_by_sentiment(no_company, 'tweet', axes)\n",
    "fig.suptitle('Word Frequencies for Each Sentiment', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b11c7f",
   "metadata": {},
   "source": [
    "* **Company only**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c152f0",
   "metadata": {},
   "source": [
    "For curiosity, let's inspect the dataframe filtered only on the ones where a product or company was included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame for only product or company\n",
    "company_only = X_train[X_train['product_or_company'] != 'undefined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc60940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting company_only DataFrame\n",
    "company_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8466bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all tweets into a single string\n",
    "company_tweets = ' '.join(no_company['tweet'].apply(lambda x: ' '.join(map(str, x))))\n",
    "\n",
    "wordcloud_graph(company_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to plot frequency by sentiment\n",
    "fig, axes = two_subplits()\n",
    "plot_distribution_by_sentiment(company_only, 'tweet', axes)\n",
    "fig.suptitle('Word Frequencies for Each Sentiment', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f35b85d",
   "metadata": {},
   "source": [
    "* **No company words**\n",
    "\n",
    "Filtering on the 'undefined' product or company still included a lot of company tokens. We will try to remove them manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d768a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of product or company name to remove\n",
    "list_of_company_products = ['google', 'android', 'apple', 'ipad', 'iphone', 'ipad2']\n",
    "# Making a copy of the dataframe to first evaluate\n",
    "no_product_company = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbdeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any word corresponding to product or company\n",
    "no_product_company['tweet'] = no_product_company['tweet'].apply(\n",
    "    lambda tweet_list: [word for word in tweet_list if word.lower() not in list_of_company_products]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b7e5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verifying if words were removed at first glance\n",
    "no_product_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba697f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Researching the tweets which refer to ipad\n",
    "word_researched = 'ipad'\n",
    "filtered_on_word = no_product_company[no_product_company['tweet'].apply(lambda tweet_list: any(word_researched in s for s in tweet_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0422423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling new dataframe filtered on word\n",
    "filtered_on_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f44c3ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Concatenating all tweets into a single string\n",
    "no_prod_comp_list = ' '.join(no_product_company['tweet'].apply(lambda x: ' '.join(map(str, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the frequencies for each sentiment\n",
    "fig, axes = two_subplits()\n",
    "plot_distribution_by_sentiment(no_product_company, 'tweet', axes)\n",
    "fig.suptitle('Word Frequencies for Each Sentiment', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting frequency for no_prod_company_tweets\n",
    "# no_product_company \n",
    "positive_tweets_no_comp = no_product_company[no_product_company['label'] == 'positive']\n",
    "negative_tweets_no_comp = no_product_company[no_product_company['label'] == 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the frequency of words without a plot: no product or company\n",
    "freq_distr(no_product_company, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the frequency of words without a plot: positive tweets only for no company or product\n",
    "freq_distr(positive_tweets_no_comp, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the frequency of words without a plot: negative tweets only for no company or product\n",
    "freq_distr(negative_tweets_no_comp, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71197292",
   "metadata": {},
   "source": [
    "Having filtered on no company tweets give us a better idea.\n",
    "\n",
    "Positive tweets talk about...\n",
    "<br>negative tweets talk about ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb5830",
   "metadata": {},
   "source": [
    "Let's review bigrams to get a better understanding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5f6ca",
   "metadata": {},
   "source": [
    "### 4: 2- h) Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dc2436",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebbd7f",
   "metadata": {},
   "source": [
    "* **All tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf483c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant package\n",
    "from nltk.collocations import *\n",
    "\n",
    "# Storing nltk.collocations.BigramAssocMeasures into variable\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892bdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9608ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to review bigrams\n",
    "def bigram_review(text, top_n):\n",
    "    # Creating a finder and passing it the words of tweets summarized as 1 list  \n",
    "    text_finder = BigramCollocationFinder.from_words(text.sum())\n",
    "    text_scored = text_finder.score_ngrams(bigram_measures.raw_freq)\n",
    "    return text_scored[: top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41456bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calling the function to review the top 20 bigrams \n",
    "bigram_review(no_product_company['tweet'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e934d4a",
   "metadata": {},
   "source": [
    "We saw earlier that the tweets containing company names or products indicated too many of of these strings, and were not relevant for us. We will straight away separate positive and negative tweets from the dataset that contains no product or company information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# They were declared before\n",
    "# positive_tweets_no_comp = no_product_company[no_product_company['label'] == 'positive']\n",
    "# negative_tweets_no_comp = no_product_company[no_product_company['label'] == 'negative']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea7a21",
   "metadata": {},
   "source": [
    "* **Positive Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ae8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to review the top 20 bigrams for positive tweets only\n",
    "bigram_review(positive_tweets_no_comp['tweet'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043d6fb",
   "metadata": {},
   "source": [
    "1. There is enthusiasm around the new pop up store created. \n",
    "<br>In addition, the fact these are temporary locations create even more envy to be there first. \n",
    "<br>This indicates that: for the launch of the folding tablet, exclusive access to SXSW attendees should be organized to create craze around the new product.  \n",
    "\n",
    "2. The new social network \"Circle\" created created a lot of curiosity as well. \n",
    "<br>We would not recommend creating a social network nowadays as the market is already mature in this area, but this can be used to know to create a specific hashtag associated with a game to win the new folding tablet. \n",
    "\n",
    "3. The speech Marissa Mayer gave was very well received. <br>Organizing a speech for this year by a respected leader in the technology market would be recommended as well.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4a8e7b",
   "metadata": {},
   "source": [
    "* **Negative Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10069f46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calling the function to review the top 20 bigrams for negative tweets only\n",
    "bigram_review(negative_tweets_no_comp['tweet'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa22145",
   "metadata": {},
   "source": [
    "### 4: 2- i) Mutual Information Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a5c03",
   "metadata": {},
   "source": [
    "We will calculate mutual information scores and we will create a frequency filter, so that we only examine bigrams that occur more than a set number of times: here, 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to calculate the mutual information scores\n",
    "def mutual_info_score(text, n_filter):\n",
    "    text_pmi_finder = BigramCollocationFinder.from_words(text.sum())\n",
    "    text_pmi_finder.apply_freq_filter(n_filter)\n",
    "    text_pmi_scored = text_pmi_finder.score_ngrams(bigram_measures.pmi)\n",
    "    return text_pmi_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13868ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function for the top 10 mutual information scores for all tweets\n",
    "mutual_info_score(no_product_company['tweet'], 5)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d294d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function for the top 10 mutual information scores for positive tweets\n",
    "mutual_info_score(positive_tweets_no_comp['tweet'], 5)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d709a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function for the top 10 mutual information scores for negative tweets\n",
    "mutual_info_score(negative_tweets_no_comp['tweet'], 5)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e0b5f",
   "metadata": {},
   "source": [
    "The mutual information scores inform us that several speakers were present, and that concerts are often talked about at SXSW.\n",
    "* Barton Hollow did a live at the conference\n",
    "* JC Penney CEO and made a speech at the conference\n",
    "* Co-Founder and TED prize winner Cameron Sinclair was present as well \n",
    "\n",
    "\n",
    "On the positive side: music events create buzz. \n",
    "* League of Extraordinary G'z were really well received\n",
    "* Security at the events is appreciated \n",
    "* The launch of galaxy ii was already talked about often, and with positive sentiments associated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070eb103",
   "metadata": {},
   "source": [
    "modeling\n",
    "<a id='modeling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f7b24a",
   "metadata": {},
   "source": [
    "## 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19244cd9",
   "metadata": {},
   "source": [
    "We now have an initial idea for recommendations for the marketing strategy. Our objective is now to:\n",
    "1. Provide more precise recommendations\n",
    "2. Develop a tool to measure the tweets' sentiments, once the strategy is deployed\n",
    "\n",
    "Because it is important to measure both sentiments: whether they are positive, or negative, the evaluation metrics we will focus on will be accuracy and F1. \n",
    "<br>In addition, the dataset is highly imbalanced: 67% of tweets are not positive. This is natural to have more reviews around negative than positives and we expect new unseen data to have similar distributions.  \n",
    "<br>Accuracy score by itself might be misleading, while F1 considers both false positives and false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7fb49",
   "metadata": {},
   "source": [
    "As the dataset is a text, it requires a transformation before it can be used for modeling. Like other types of dataset would one-hot encoded, here, the tweets were vectorized, using the common method in natural language processing: `TfidfVectorizer`.  \n",
    "<br> It converts a collection of text documents to a matrix of tf-idf features. \n",
    "\n",
    "* Term-Frequency\n",
    "<br>Measures how often a term (word) appears in a document\n",
    "* Inverse Document Frequency (IDF)\n",
    "<br>Measures the importance of a term in the entire collection of documents. \n",
    "\n",
    "4 main classification models were explored: \n",
    "1. Multinomial Naive Bayes\n",
    "2. Decision Tree\n",
    "3. Random Forest \n",
    "4. K-Nearest Neighbor \n",
    "\n",
    "The models' parameters were tuned using the following approaches:\n",
    "1. Under Sampling\n",
    "2. Hyperparameter Tuning\n",
    "    * Combinatoric Grid Searching\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c308a97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reminding the natural balance\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24605651",
   "metadata": {},
   "source": [
    "By using only the dataset's natural class balance, and if we guessed the contribution of the majority class every time we would get 67% accuracy. However, if we were to guess that a tweet was positive, we would expect only about 33% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9842e",
   "metadata": {},
   "source": [
    "### 5. a) Baseline Model with TfidfVectorizer and MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96e24d",
   "metadata": {},
   "source": [
    "The first baseline model will vectorize the tweets and make predictions using Multinomial Naive Bayes. The first step is to import the vectorizer, instantiate a vectorizer object and fit it on `X_train['tweet']`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac95420",
   "metadata": {},
   "source": [
    "### <u>1st iteration</u>: Tfidf Vectorizer with Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55178d",
   "metadata": {},
   "source": [
    "    1) Fitting and training on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant packages\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Define the pipeline steps\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "\n",
    "# Create the pipeline\n",
    "base_pipeline = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('classifier', naive_bayes_classifier)\n",
    "])\n",
    "\n",
    "# Fitting the pipeline on X_train['tweet_original'] and y_train\n",
    "base_pipeline.fit(X_train['tweet_original'], y_train)\n",
    "\n",
    "# Calculating predictions using this model\n",
    "base_y_pred = base_pipeline.predict(X_test['tweet_original'])\n",
    "\n",
    "# Optionally, you can access the individual components of the pipeline:\n",
    "X_train_vectorized = base_pipeline.named_steps['tfidf'].transform(X_train['tweet_original'])\n",
    "baseline_model = base_pipeline.named_steps['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d03d8",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e73902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant packages\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluation_metrics(y_test, y_pred, model, X, y):\n",
    "    with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    # Calculating and printing accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Calculating and printing F1-score\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f'F1-Score: {f1:.4f}')\n",
    "    \n",
    "    # Calculating and printing precision\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "\n",
    "    # Performing cross-validation and printing the mean accuracy\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    mean_cv_accuracy = cv_scores.mean()\n",
    "    print(f'Mean Cross-Validated Accuracy: {mean_cv_accuracy:.4f}')\n",
    "    \n",
    "    return accuracy, f1, precision, mean_cv_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b8593",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Naming the model and calling the function to evaluate it\n",
    "baseline_model_name = 'Baseline'\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_base, precision_base, f1_base, cv_base = evaluation_metrics(\n",
    "    y_test, \n",
    "    base_y_pred, \n",
    "    base_pipeline, \n",
    "    X_train['tweet_original'], \n",
    "    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632329da",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to print a classification report\n",
    "\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def class_calculation(y_test, y_pred):\n",
    "    # y_preds will be calculated for each model beforehand \n",
    "    \n",
    "    # Generating and printing classification report\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    class_report = classification_report(y_test, y_pred, zero_division=0, digits=5)\n",
    "    \n",
    "    # Due to class imbalance, the initial precision for positive returns 0 \n",
    "    # Consequently, warnings need to be handled \n",
    "    print('Classification Report:\\n', class_report)\n",
    "    return class_report\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to record the classification report\n",
    "base_class_report = class_calculation(y_test, base_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2146e",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30780508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Defining a colormap that interpolates between the two defined colors\n",
    "custom_colors_cnf = ['#3F3533', '#F5F2EE']\n",
    "\n",
    "n_bins = 20 \n",
    "\n",
    "# Creating the custom colormap\n",
    "custom_cmap_cnf = LinearSegmentedColormap.from_list(\"custom_cmap\", custom_colors_cnf, N=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying visually the confusion matrix \n",
    "\n",
    "# Importing the relevant package \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "def confusion_matrix_display(model, y_test, y_pred):\n",
    "    # Defining the confusion matrix \n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "#     print(cnf_matrix)\n",
    "    \n",
    "    # Normalizing the confusion matrix\n",
    "    cnf_matrix_normalized = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix_normalized, display_labels=model.classes_)\n",
    "\n",
    "    disp.plot(cmap=custom_cmap_cnf)\n",
    "\n",
    "    plt.title(\"Model Performance: Confusion Matrix\", fontsize=16)\n",
    "\n",
    "    # Saving the plot as a PNG with a transparent background\n",
    "    plt.savefig('images/confusion_matrix.png', transparent=True)\n",
    "\n",
    "    return cnf_matrix\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ea926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to display the confusion matrix \n",
    "base_cfn_matrix = confusion_matrix_display(base_pipeline, y_test, base_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49bdbd",
   "metadata": {},
   "source": [
    "### <u>2nd iteration</u>: Addressing class imbalance: undersampling negative tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a6395",
   "metadata": {},
   "source": [
    "    1) Fitting and training on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8cb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import imblearn.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef71e5",
   "metadata": {},
   "source": [
    "Now that we have preprocessed data, we will fit and evaluate the baseline model on the newly resampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b382d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pipeline steps\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "\n",
    "# Including the UnderSampler to the pipeline\n",
    "rs_pipeline = imblearn.pipeline.Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('us', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', naive_bayes_classifier)\n",
    "])\n",
    "\n",
    "# Fitting the pipeline on X_train['tweet_original'] and y_train\n",
    "rs_pipeline.fit(X_train['tweet_original'], y_train)\n",
    "\n",
    "rs_y_pred = rs_pipeline.predict(X_test['tweet_original']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the value counts of each category, before undersampling\n",
    "original_value_counts = y_train.value_counts()\n",
    "print(\"Original class distribution:\")\n",
    "print(original_value_counts)\n",
    "\n",
    "# Getting the indices of the resampled data\n",
    "resampled_indices = rs_pipeline.named_steps['us'].sample_indices_\n",
    "\n",
    "# Verifying the new value counts of each category, after undersampling\n",
    "resampled_value_counts = y_train.iloc[resampled_indices].value_counts()\n",
    "print(\"\\nClass distribution after undersampling:\")\n",
    "print(resampled_value_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578437f6",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138dff63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Naming the model\n",
    "resampled_model_name = 'Resampled'\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_rs, f1_rs, precision_rs, cv_rs = evaluation_metrics(\n",
    "    y_test, \n",
    "    rs_y_pred, \n",
    "    rs_pipeline, \n",
    "    X_train['tweet_original'], \n",
    "    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c0aa7",
   "metadata": {},
   "source": [
    "The accuracy score drastically decreased, but we now have a precision and f1 scores, indicating the 'positive sentiments' are now correctly represented.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480113c",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "resamp_class_report = class_calculation(y_test, rs_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5848d943",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8011574",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rs_cfn_matrix = confusion_matrix_display(rs_pipeline, y_test, rs_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9031b8",
   "metadata": {},
   "source": [
    "### <u>4th iteration</u>: including stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba67ac7",
   "metadata": {},
   "source": [
    "    1) Fitting and training train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ebb76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pipeline steps, including the stopwords_list created \n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10, stop_words=stopwords_list)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "\n",
    "# Instantiating the pipeline with the undersampler and the new vectorizer\n",
    "pipeline_nostop = imblearn.pipeline.Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('us', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', naive_bayes_classifier)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on X_train['tweet_original'] and y_train\n",
    "pipeline_nostop.fit(X_train['tweet_original'], y_train)\n",
    "\n",
    "# Generating predictions\n",
    "nostop_y_pred = pipeline_nostop.predict(X_test['tweet_original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be211251",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the model\n",
    "nostop_model_name = 'No Stopwords'\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_nostop, f1_nostop, precision_nostop, cv_nostop = evaluation_metrics(\n",
    "    y_test, \n",
    "    nostop_y_pred, \n",
    "    pipeline_nostop, \n",
    "    X_train['tweet_original'], \n",
    "    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722976a4",
   "metadata": {},
   "source": [
    "The accuracy score increased slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813c7a4",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c53d161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling the classification function\n",
    "nostop_class_report = class_calculation(y_test, nostop_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4da9f",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf842c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calling the confusion matrix function\n",
    "nostop_cfn_matrix = confusion_matrix_display(pipeline_nostop, y_test, nostop_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f27b2e",
   "metadata": {},
   "source": [
    "### <u>5th iteration</u>: Applying the full preprocessing to tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0483370",
   "metadata": {},
   "source": [
    "    1) Fitting and training train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb32df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applying stopwords to the vectorizer, as they were applied to the preprocessed tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pipeline steps \n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "\n",
    "# Instantiating the pipeline with the undersampler and the new vectorizer\n",
    "pipeline_prep = imblearn.pipeline.Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('us', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', naive_bayes_classifier)\n",
    "])\n",
    "\n",
    "# Fitting the pipeline on X_train['tokenized tweet'] which contains the preprocessed tweets\n",
    "pipeline_prep.fit(X_train['tokenized_tweet'], y_train)\n",
    "\n",
    "# Generating predictions\n",
    "prep_y_pred = pipeline_prep.predict(X_test['tokenized_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c7ddc",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_model_name = 'Preprocessed'\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_pp, f1_pp, precision_pp, cv_pp = evaluation_metrics(\n",
    "    y_test, \n",
    "    prep_y_pred, \n",
    "    pipeline_prep, \n",
    "    X_train['tokenized_tweet'], \n",
    "    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2e5a0",
   "metadata": {},
   "source": [
    "The accuracy score increased slightly, but precision decreased. F1 increased but Cross Validated Accuracy decreased. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80847acd",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791caf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing the classification report \n",
    "prep_class_report = class_calculation(y_test, prep_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb5aeb",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac06b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix\n",
    "prep_cnf_matrix = confusion_matrix_display(pipeline_prep, y_test, prep_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e0452",
   "metadata": {},
   "source": [
    "### <u>6th iteration</u>: Tuning Tfidf Vectorizer - Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a85a64",
   "metadata": {},
   "source": [
    "    1) Fitting and training train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879670de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defining the pipeline steps, excluding any manual input of features, with the vectorizer and classifier\n",
    "# The pipeline still includes the undersampler to ensure class imbalance\n",
    "gs_pipeline = imblearn.pipeline.Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('us', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "parameters = {\n",
    "    'tfidf__max_features': [10, 50, 100, None],\n",
    "    'tfidf__max_df': [0.7, 0.8, 0.9],\n",
    "    'tfidf__min_df': [1, 2, 3],\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    # including the list of stopwords that was defined earlier \n",
    "    'tfidf__stop_words': [None, 'english', stopwords_list],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing grid search for hyperparameter tuning\n",
    "grid_search = GridSearchCV(gs_pipeline, parameters, cv=5, scoring='accuracy', error_score='raise')\n",
    "\n",
    "# Fitting the tuned pipeline on training data\n",
    "grid_search.fit(X_train['tweet_original'], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording the best parameters and printing them\n",
    "best_tfidf_params = grid_search.best_params_\n",
    "\n",
    "# Recording the best estimator as the best_pipeline\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", best_tfidf_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the best pipeline on training data\n",
    "best_pipeline.fit(X_train['tweet_original'], y_train)\n",
    "\n",
    "# Fitting the best model on the full training data\n",
    "best_gs_y_pred = best_pipeline.predict(X_test['tweet_original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db4833",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891dee3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Naming the model\n",
    "tuned_model_name = 'Tuned NB'\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_gs, f1_gs, precision_gs, cv_gs = evaluation_metrics(\n",
    "    y_test, \n",
    "    best_gs_y_pred, \n",
    "    best_pipeline, \n",
    "    X_train['tweet_original'], \n",
    "    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05aba74",
   "metadata": {},
   "source": [
    "The classification metrics are starting to increase and are starting to show more stability, less disparity among one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c6793",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c8a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling the classification report function\n",
    "tuned_class_report = class_calculation(y_test, best_gs_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef87138",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0cf28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix\n",
    "gs_cfn_matrix = confusion_matrix_display(best_pipeline, y_test, best_gs_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f320c",
   "metadata": {},
   "source": [
    "### 5. b) TfidfVectorizer and Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ce3ec",
   "metadata": {},
   "source": [
    "### <u>7th iteration</u>: Decision Tree Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b25ad",
   "metadata": {},
   "source": [
    "Decision trees work well for understanding language because they are easy to interpret and handle the nuances in how words relate. They are good at understanding what words matter most and can deal with different types of word data without much difficulty. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e4e96",
   "metadata": {},
   "source": [
    "    1) Fitting and training train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe42a58",
   "metadata": {},
   "source": [
    "For higher computing performance, the best parameters recorded on the vectorizer with Multinomial Naive Bayes will be kept. Only the classifier will be modified. Let's see if, by using the best TFIDF parameters with another classifier, we can improve further these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670eb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the best vectorizer parameters \n",
    "print(best_tfidf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9000b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that modifies the parameters, to allow them to be used for future classifiers\n",
    "def transform_params(best_params):    \n",
    "    new_best_params = {}\n",
    "    for key, value in best_params.items():\n",
    "        # Removing 'tfidf__' from the key\n",
    "        new_key = key.replace('tfidf__', '')\n",
    "        new_best_params[new_key] = value\n",
    "    return new_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the newly defined parameters \n",
    "new_best_tfidf_params = transform_params(best_tfidf_params)\n",
    "\n",
    "# Inspecting them\n",
    "print(new_best_tfidf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a4c58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the relevant packages\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Defining the pipeline with new classifier, but the same best parameters\n",
    "dt_pipeline = imblearn.pipeline.Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(**new_best_tfidf_params)),\n",
    "    ('us', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Fitting the pipeline on training data\n",
    "dt_pipeline.fit(X_train['tweet_original'], y_train)\n",
    "\n",
    "# Making predictions on test data\n",
    "dt_y_pred = dt_pipeline.predict(X_test['tweet_original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551a153",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the model\n",
    "dt_model_name = 'DecisionTree'\n",
    "\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_dt, f1_dt, precision_dt, cv_dt = evaluation_metrics(\n",
    "    y_test,\n",
    "    dt_y_pred,\n",
    "    dt_pipeline,\n",
    "    X_train['tweet_original'],\n",
    "    y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f82891",
   "metadata": {},
   "source": [
    "All scores slightly increased and remain consistent. Whether it is accuracy, F1, precision or the cross-validated accuracy, they are all in the 0.66 range as opposed to the previously recorded results. \n",
    "Cross-validated accuracy was in the 0.64 range, while precision was over 0.68."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88969936",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff2ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling the classification report function\n",
    "class_report_dt = class_calculation(y_test, dt_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a09c0",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df933ec8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recording and displaying the confusion matrix\n",
    "dt_cfn_matrix = confusion_matrix_display(dt_pipeline, y_test, dt_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81d43a",
   "metadata": {},
   "source": [
    "The model correctly identified 46% of positive tweets, but 77% of negative tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf41309",
   "metadata": {},
   "source": [
    "### 5. c) TfidfVectorizer and Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e4a70",
   "metadata": {},
   "source": [
    "### <u>8th iteration</u>: RandomForestClassifierTuning Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfec352",
   "metadata": {},
   "source": [
    "    1) Fitting and training on train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131cdb34",
   "metadata": {},
   "source": [
    "Random Forest classifiers are a sort of extension of multiple decision trees working together together to understand language text.Let's see if, by using the best TFIDF parameters with another classifier, we can improve further these predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0bdc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant package\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Defining the pipeline with the fixed tfidf parameters and RandomForestClassifier\n",
    "rf_pipeline = imblearn.pipeline.Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(**new_best_tfidf_params)),\n",
    "    ('us', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fitting the pipeline on training data\n",
    "rf_pipeline.fit(X_train['tweet_original'], y_train)\n",
    "\n",
    "# Making predictions on test data\n",
    "rf_y_pred = rf_pipeline.predict(X_test['tweet_original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787302f",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the model and calling the function to evaluate it\n",
    "rf_tuned_model_name = 'RandomForest'\n",
    "\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_rf, f1_rf, precision_rf, cv_rf = evaluation_metrics(\n",
    "    y_test,\n",
    "    rf_y_pred,\n",
    "    rf_pipeline,\n",
    "    X_train['tweet_original'],\n",
    "    y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11075e9",
   "metadata": {},
   "source": [
    "The overall scores increased, recording the highest F1 Score reached. \n",
    "The model still has difficulty identifying positive tweets due to the dataset imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91ce0d",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e02d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling the classification report function\n",
    "rf_class_report = class_calculation(y_test, rf_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e549ea80",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80799e8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recording and displaying the confusion matrix\n",
    "rf_confusion_matrix = confusion_matrix_display(rf_pipeline, y_test, rf_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f9bf71",
   "metadata": {},
   "source": [
    "The overall scores increased, recording the highest F1 Score reached. \n",
    "The model still has difficulty identifying positive tweets due to the dataset imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfedd35e",
   "metadata": {},
   "source": [
    "### 5. d) TfidfVectorizer and K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d5ee4",
   "metadata": {},
   "source": [
    "### <u>9th iteration</u>: K-Nearest Neighbor Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00150b65",
   "metadata": {},
   "source": [
    "    1) Fitting and training on train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c0d33",
   "metadata": {},
   "source": [
    "The previous model was a bit computationally expensive. Let's see if the simpler K-Nearest Neighbor classifier would improve on that end. Nevertheless, kNN makes predictions based on what similar cases around it suggest so there is a risk it captures more noise created by the imbalanced dataset, despite the undersampled negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a400f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Defining the pipeline with the fixed tfidf parameters and RandomForestClassifier\n",
    "knn_pipeline = imblearn.pipeline.Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(**new_best_tfidf_params)),\n",
    "    ('us', RandomUnderSampler(random_state=42)),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Fitting the pipeline on training data\n",
    "knn_pipeline.fit(X_train['tweet_original'], y_train)\n",
    "\n",
    "# Making predictions on test data\n",
    "knn_y_pred = knn_pipeline.predict(X_test['tweet_original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f9799",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37948c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the model and calling the function to evaluate it\n",
    "knn_tuned_model_name = 'kNN'\n",
    "\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_knn, precision_knn, f1_knn, cv_knn = evaluation_metrics(\n",
    "    y_test,\n",
    "    knn_y_pred,\n",
    "    knn_pipeline,\n",
    "    X_train['tweet_original'],\n",
    "    y_train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00191a67",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca1849",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calling the function\n",
    "knn_class_report = class_calculation(y_test, knn_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e2b45",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e894a6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recording and displaying the confusion matrix\n",
    "knn_confusion_matrix = confusion_matrix_display(knn_pipeline, y_test, knn_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a463a6",
   "metadata": {},
   "source": [
    "The F1 score highly decreased compared to the Random Forest model. Indeed, the model correctly predicted 98% of negative tweets as negative - which makes sense: kNN looks at similar cases to make predictions. \n",
    "\n",
    "However the actual positive tweets predicted decreased to 8%. This model cannot be kept at the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029ee9e",
   "metadata": {},
   "source": [
    "evaluation\n",
    "<a id='evaluation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48489914",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a409a68",
   "metadata": {},
   "source": [
    "### 6. a) Final Model and Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc6f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the best model in the associated variable\n",
    "best_model = rf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd3775",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Viewing the best parameters defined by Combinatoric Grid Searching \n",
    "best_tfidf_params = new_best_tfidf_params\n",
    "print(list(best_tfidf_params.items())[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c43aac",
   "metadata": {},
   "source": [
    "### 6. b) Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c860fdc",
   "metadata": {},
   "source": [
    "    2) Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea8ebd",
   "metadata": {},
   "source": [
    "* Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the model and calling the function to evaluate it\n",
    "best_model_name = 'RandomForest'\n",
    "\n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "accuracy_rf, precision_rf, f1_rf, cv_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39576219",
   "metadata": {},
   "source": [
    "* Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f812c8",
   "metadata": {},
   "source": [
    "As we have evaluated the models, we will run our function again. The same results are expected for the first 3 metrics, only the cross-validated accuracy should change as this one will be evaluated on the test, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e44774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming the model and calling the function to evaluate it\n",
    "best_model_name = 'RandomForest'\n",
    "# best_pipeline = \n",
    "\n",
    "# Calling the function and recording into the defined values\n",
    "test_accuracy_best, test_precision_best, test_f1_best, test_cv_best = evaluation_metrics(\n",
    "    y_test,\n",
    "    rf_y_pred,\n",
    "    best_model,\n",
    "    X_test['tweet_original'],\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc48cf",
   "metadata": {},
   "source": [
    "    3) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9d373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling the function\n",
    "rf_class_report = class_calculation(y_test, rf_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdac8a7",
   "metadata": {},
   "source": [
    "    4) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f077d74b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Recording and displaying the confusion matrix\n",
    "rf_confusion_matrix = confusion_matrix_display(best_model, y_test, rf_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74682f",
   "metadata": {},
   "source": [
    "The model is slightly overfitting, which suggests that the model may be capturing noise in the training data that doesn't generalize well to unseen data. This might be due to undersampling of negative tweets. In a further modelling process, two options should be considered:\n",
    "1. Stratified Undersampling\n",
    "<br>Stratified undersampling may protect from the importance given to single words, by keeping the ratio of words or token\n",
    "2. Synthetic Minority Oversampling\n",
    "<br> In addition to undersampling tweets to a certain level, positive tweets should be synthetically oversampled as well to try to draw better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing all models metrics into corresponding lists \n",
    "models = [baseline_model_name, resampled_model_name, nostop_model_name, preprocessed_model_name, tuned_model_name, dt_model_name, rf_tuned_model_name, knn_tuned_model_name] \n",
    "accuracy_metrics = [accuracy_base, accuracy_rs, accuracy_nostop, accuracy_pp, accuracy_gs, accuracy_dt, accuracy_rf, accuracy_knn]\n",
    "precision_metrics = [precision_base, precision_rs, precision_nostop, precision_pp, precision_gs, precision_dt, precision_rf, precision_knn]\n",
    "f1_metrics = [f1_base,  f1_rs, f1_nostop, f1_pp, f1_gs, f1_dt, f1_rf, f1_knn]\n",
    "cv_metrics = [cv_base, cv_rs, cv_nostop, cv_pp, cv_gs, cv_dt, cv_rf, cv_knn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying that all lists have the same size\n",
    "# print(len(models))\n",
    "# print()\n",
    "# print(len(accuracy_metrics))\n",
    "# print()\n",
    "# print(len(precision_metrics))\n",
    "# print()\n",
    "# print(len(f1_metrics))\n",
    "# print()\n",
    "# print(len(cv_metrics))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd428e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with stored best scores \n",
    "models = models\n",
    "\n",
    "data = {\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracy_metrics,\n",
    "    'F1': f1_metrics,\n",
    "    'Precision': precision_metrics,\n",
    "    'Cross-val accuracy': cv_metrics\n",
    "}\n",
    "\n",
    "overall = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53caf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the newly created dataframe\n",
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b95ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar chart to review all\n",
    "\n",
    "#  Creating a bar chart for Precision\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,6))\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "plt.bar(overall['Model'], overall['F1'], color='#3F3533', label='F1')\n",
    "\n",
    "# Creating line plots for Log Loss and Accuracy\n",
    "plt.plot(overall['Model'], overall['Accuracy'], marker='o', color='#7FD1AE', label='Accuracy')\n",
    "plt.plot(overall['Model'], overall['Cross-val accuracy'], marker='x', color='#FF8A5E', label='CV')\n",
    "\n",
    "# Setting labels and title\n",
    "plt.xlabel('Models')\n",
    "# plt.ylabel('Precision')\n",
    "plt.ylabel('Precision, Accuracy, CV')\n",
    "\n",
    "\n",
    "    \n",
    "# Annotating the last index of each category\n",
    "plt.annotate(f'F1: {f1_metrics[6] * 100:.2f}%', (models[6], f1_metrics[6] + 0.01), ha='center', va='bottom')\n",
    "plt.annotate(f'{accuracy_metrics[6] * 100:.2f}%', (models[6], overall['Accuracy'][6] - 0.07), ha='center', va='bottom', color='#7FD1AE')\n",
    "plt.annotate(f'{cv_metrics[6] * 100:.2f}%', (models[6], overall['Cross-val accuracy'][6] - 0.11), ha='center', va='bottom', color='#FF8A5E')\n",
    "\n",
    "\n",
    "    \n",
    "# Defining the max value of y \n",
    "max_y = max(overall[['F1', 'Accuracy']].max())\n",
    "plt.ylim(0, max_y  + 0.15)\n",
    "plt.title('Classification Metrics for All Selected Models', fontsize=16)\n",
    "\n",
    "# Displaying the legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ax.set_facecolor('#F5F2EE')\n",
    "# Saving the plot as a PNG with a transparent background\n",
    "# plt.savefig('images/final_model.png')\n",
    "\n",
    "\n",
    "plt.figure().patch.set_facecolor('#F5F2EE')\n",
    "\n",
    "# Showing the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a7eff",
   "metadata": {},
   "source": [
    "<u>Only the top 3 models</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To represent the above graph more easily on the client's presentation, we will store only the top 3 models \n",
    "top_3_models = overall[overall['F1'] > 0.65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying only 3 models were stored\n",
    "top_3_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee635656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar chart to review all\n",
    "\n",
    "#  Creating a bar chart for F1\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,6))\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_3_models['Model'], top_3_models['F1'], color='#3F3533', label='F1')\n",
    "\n",
    "# Creating line plots for Log Loss aand Accuracy\n",
    "plt.plot(top_3_models['Model'], top_3_models['Accuracy'], marker='o', color='#7FD1AE', label='Accuracy', linewidth=4, linestyle='--')\n",
    "plt.plot(top_3_models['Model'], top_3_models['Cross-val accuracy'], marker='x', color='#FF8A5E', label='CV')\n",
    "\n",
    "# Setting labels and title\n",
    "plt.xlabel('Models')\n",
    "# plt.ylabel('F1')\n",
    "plt.ylabel('F1, Accuracy, CV')\n",
    "    \n",
    "# Annotating the last index of each category\n",
    "plt.annotate(f'F1: {f1_metrics[6] * 100:.2f}%', (models[6], f1_metrics[6] + 0.01), ha='center', va='bottom')\n",
    "plt.annotate(f'{accuracy_metrics[6] * 100:.2f}%', (models[6], top_3_models['Accuracy'][6] - 0.03), ha='center', va='bottom', color='#7FD1AE')\n",
    "plt.annotate(f'{cv_metrics[6] * 100:.2f}%', (models[6], top_3_models['Cross-val accuracy'][6] - 0.05), ha='center', va='bottom', color='#FF8A5E')\n",
    "\n",
    "\n",
    "    \n",
    "# Defining the max value of y \n",
    "max_y = max(top_3_models[['F1', 'Accuracy']].max())\n",
    "plt.ylim(0.4, max_y  + 0.1)\n",
    "plt.title('Classification Metrics for Top 3 Models', fontsize=16)\n",
    "\n",
    "# Displaying the legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ax.set_facecolor('#F5F2EE')\n",
    "# Saving the plot as a PNG with a transparent background\n",
    "\n",
    "\n",
    "plt.figure().patch.set_facecolor('#F5F2EE')\n",
    "\n",
    "# Saving picture\n",
    "plt.savefig('images/final_model.png')\n",
    "\n",
    "\n",
    "# Showing the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570161ef",
   "metadata": {},
   "source": [
    "**Evaluation of Positive Tweets about Technology Brands at South by Southwest**:\n",
    "\n",
    "The best model for predicting positive tweets about the best technology brands at South by Southwest was determined to be the Tfidf Vectorizer in conjunction with a Random Forest classifier. The hyperparameters for the Tfidf Vectorizer were fine-tuned using Combinatoric Gridsearch. The chosen model yielded the following impressive metrics:\n",
    "\n",
    "\n",
    "<br><br>These metrics showcase the robust performance of the model, particularly in terms of precision and accuracy, indicating its ability to effectively identify positive sentiments related to technology brands during the South by Southwest event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0894de2",
   "metadata": {},
   "source": [
    "findings_n_recommendations\n",
    "<a id='findings_n_recommendations'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60006f49",
   "metadata": {},
   "source": [
    "## 7. Findings & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1b432",
   "metadata": {},
   "source": [
    "### 7. a) Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a colormap specifically for the top features bar graph\n",
    "custom_colors = ['#F5F2EE','#B3A6A4', '#8A7E7C', '#635856', '#3F3533']\n",
    "\n",
    "n_bins = 200\n",
    "\n",
    "# Creating the custom colormap\n",
    "features_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", custom_colors, N=n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441757f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "\n",
    "# Visualizing feature importances with automatically determined colors and sorted in descending order\n",
    "def plot_top_feature_importances(pipeline, top_n):\n",
    "    # Accessinf the classifier instance from the pipeline\n",
    "    classifier = pipeline.named_steps['classifier']\n",
    "    \n",
    "    # Getting the feature names from the vectorizer\n",
    "    feature_names = pipeline.named_steps['tfidf'].get_feature_names_out()\n",
    "\n",
    "    # Getting the feature importances\n",
    "    feature_importances = classifier.feature_importances_\n",
    "\n",
    "    # Sorting feature importances in descending order and get the corresponding indices\n",
    "    sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "    # Selecting the top 'top_n' features\n",
    "    top_indices = sorted_indices[:top_n]\n",
    "\n",
    "    # Sorting the feature names based on the selected top indices\n",
    "    top_feature_names = feature_names[top_indices]\n",
    "\n",
    "    # Sorting the feature importances for the selected top features\n",
    "    top_feature_importances = feature_importances[top_indices]\n",
    "\n",
    "    # Reverse the order to make it descending\n",
    "    top_feature_names = top_feature_names[::-1]\n",
    "    top_feature_importances = top_feature_importances[::-1]\n",
    "    \n",
    "\n",
    "    # Creating a colormap\n",
    "    cmap = plt.get_cmap(features_cmap)\n",
    "\n",
    "    # Manually normalizing importance values\n",
    "    normalized_importances = (top_feature_importances - np.min(top_feature_importances)) / (np.max(top_feature_importances) - np.min(top_feature_importances))\n",
    "\n",
    "    # Creating the figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Using normalized_importances directly for color mapping\n",
    "    bars = ax.barh(range(top_n), top_feature_importances, align='center', color=cmap(normalized_importances))\n",
    "    plt.yticks(range(top_n), top_feature_names)\n",
    "    plt.xlabel('Feature importance', labelpad=20)\n",
    "    plt.ylabel('Feature', fontsize=12, labelpad=20)\n",
    "    plt.title('Most Important Features: Top {}'.format(top_n), fontsize=16)\n",
    "\n",
    "    # Adding a colorbar to the right of the plot\n",
    "    sm = ScalarMappable(cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    colorbar = plt.colorbar(sm, ax=ax, orientation='vertical', aspect=30)\n",
    "    # Hide colorbar ticks\n",
    "    # Defining custom tick positions\n",
    "    custom_ticks = [0, 0.5, 1]\n",
    "    custom_ticklabels = ['Low', 'Medium', 'High']\n",
    "    colorbar.set_ticks(custom_ticks)\n",
    "    colorbar.set_ticklabels(custom_ticklabels)\n",
    "    plt.show()\n",
    "    return top_feature_names[::-1] \n",
    "    \n",
    "# Saving picture\n",
    "plt.savefig('images/most_important_features.png')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Calling the function with the best model\n",
    "top_10_features = plot_top_feature_importances(best_model, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a60a23",
   "metadata": {},
   "source": [
    "The most important features for the model help us gather the main themes and make the recommendations previously identified, more precise: \n",
    "\n",
    "\n",
    "1. apple store, pop up store, apple pop: \n",
    "    <br>Attendees were impressed with the how long lines were becoming to buy the new ipad. \n",
    "    <br>This created even more curiosity and people wanted even more to be among the first ones to buy the new iPad 2.\n",
    "2. iphone app, ipad app: \n",
    "    <br> The app created for the SXSW conference was highly appreciated\n",
    "    <br> It made attendees talk about the brand: this is an easy way to create 'free' communication around your brand\n",
    "3. google circles, social network: \n",
    "    <br> The new social network created by Google created eagerness. \n",
    "    <br> Social networks since 2013 have highly evolved and this market has reached its maturity. \n",
    "    <br>Instead, the recommendation here would be to build a hashtag to hope to win the new tablet at the event \n",
    "4. google party:\n",
    "    <br>The party was highly enjoyed. To ensure attendees go to the party, mix the previous recommendation with the party: use the hashtag created for the chance to get access to concert, where the tablet will be released. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606bf27d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspecting the returned top 10 features \n",
    "top_10_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e8169",
   "metadata": {},
   "source": [
    "We will now create X_positive DataFrame. This will allow us to review the tweets for each the top 10 features by importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba28fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating  dataframe to glance through the tweets containing the top 10 most important features to validate our recommendations  \n",
    "X_positive = X_train[y_train == 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_positive[X_positive['tweet_original'].str.contains('apple store')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c05264",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspecting the tweets related to top 10 features  \n",
    "for feature in top_10_features:\n",
    "    print(feature.upper())\n",
    "    print()\n",
    "    print(X_positive[X_positive['tweet_original'].str.contains(feature)][['tweet_original']][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the vectorized tweets as an array and transforming it to a list\n",
    "feature_names_list = rf_pipeline.named_steps['tfidf'].get_feature_names_out().tolist()\n",
    "\n",
    "# Concatenating the feature names into a single string\n",
    "vectorized_tweets = ' '.join(feature_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed79db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty DataFrame to store the tweets related to the top features\n",
    "dfs_to_concat = []\n",
    "\n",
    "# Iterating through the top features\n",
    "for feature_name in top_10_features:\n",
    "    # Filter tweets containing the current top feature\n",
    "    matching_tweets = X_positive[X_positive['tweet_original'].str.contains(feature_name)]\n",
    "    \n",
    "    # Appending matching tweets to the list\n",
    "    dfs_to_concat.append(matching_tweets)\n",
    "\n",
    "# Concatenating the list of DataFrames into a single DataFrame\n",
    "X_positive_top_features = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "\n",
    "# Print or use X_positive_top_features as needed\n",
    "X_positive_top_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a705ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining list of product or company name to remove\n",
    "list_of_company_products = ['google', 'android', 'apple', 'ipad', 'iphone', 'ipad2', 'iphone ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36acd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the created DataFrame\n",
    "nocomp_positive_top_features = X_positive_top_features.copy()\n",
    "nocomp_positive_top_features[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any word corresponding to product or company\n",
    "nocomp_positive_top_features['tweet'] = nocomp_positive_top_features['tweet'].apply(\n",
    "    lambda tweet_list: [word for word in tweet_list if word.lower() not in list_of_company_products]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147219d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the newly created column\n",
    "nocomp_positive_top_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all tweets into a single string\n",
    "top_feature_tweets_nocomp = ' '.join(nocomp_positive_top_features['tweet'].apply(lambda x: ' '.join(map(str, x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb950c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Printing a new wordcloud to review if any visual representation can be easier this way\n",
    "wordcloud_graph(top_feature_tweets_nocomp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d5583",
   "metadata": {},
   "source": [
    "The main words that were identified before are confirmed visually here: the main reference is the ipad - which would be our intention for the folding tablet. \n",
    "\n",
    "The social network is identified again, which shows the enthusiasm around it. \n",
    "\n",
    "Similar approaches show for the apple store, the pop-up store and overall the fact that the launch was major. This is the kind of theme we want for Samsung. \n",
    "\n",
    "Nevertheless, without more contact, it is difficult to use this wordcloud on a presentation and understand why this helped us make recommendations, so this visual will not be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e42698",
   "metadata": {},
   "source": [
    "### 7. c) Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b153038",
   "metadata": {},
   "source": [
    "To generate buzz around the launch of Samsung's new folding tablet, consider implementing the following key strategies:\n",
    "\n",
    "1. In-Person Sales and Pop-Up Stores:\n",
    "\n",
    "    * Offer exclusive early access to SXSW attendees, creating a sense of urgency and desire.\n",
    "    * Establish pop-up stores within the conference venue to further engage and captivate potential buyers.\n",
    "    * Foster anticipation by orchestrating lines, enhancing the overall attraction and exclusivity.\n",
    "    * Innovative Conference App:\n",
    "\n",
    "2. Develop a cutting-edge mobile app for both phones and tablets, enhancing conference access and engagement.\n",
    "    * Leverage the app to tap into attendees' creativity, creating a platform for discussion and interaction.\n",
    "\n",
    "3. Strategic Hashtag Campaign:\n",
    "    * Take inspiration from the excitement around social network launches, such as Google Circles, by creating a dedicated hashtag.\n",
    "    * Recognize the evolving landscape of social networks and harness the hashtag to generate excitement and participation.\n",
    "    * Position the hashtag as a means to win the new tablet, fostering eagerness among the audience.\n",
    "\n",
    "4. Exclusive Party Integration:\n",
    "\n",
    "    * Utilize the app to create exclusivity, making it a prerequisite for access to an exclusive party.\n",
    "    (Blend the party experience with the hashtag campaign, encouraging attendees to use the hashtag for a chance to access the tablet release concert).\n",
    "    * Strive to surpass the success of the previous year's concert, ensuring the party becomes a highlight of the event.\n",
    "\n",
    "\n",
    "These refined strategies aim to capture the essence of successful past events, combining physical presence, technological innovation, social media engagement, and exclusive experiences to maximize the impact of the tablet launch at the SXSW conference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a314f4",
   "metadata": {},
   "source": [
    "limits_n_next_steps\n",
    "<a id='limits_n_next_steps'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ade41",
   "metadata": {},
   "source": [
    "## 8. Limits & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8065e3",
   "metadata": {},
   "source": [
    "Despite providing us a good idea for recommendations, the accuracy and F1 score remain low, we would aim at reaching above 70%. \n",
    "\n",
    "To do this in the future we would:\n",
    "* Synthetically Oversample the Minority class\n",
    "<br> In addition to undersampling tweets to a certain level, positive tweets should be synthetically oversampled as well to try to draw better results. \n",
    "\n",
    "* Stratified Undersampling:\n",
    "<br> Stratified undersampling may protect from the importance given to single words, by keeping the ratio of words or token\n",
    "\n",
    "* Hyperparameters Tuning\n",
    "<br> We searched best parameters for the vectorizer only, but not for the classifier. By changing these, the accuracy, could be improved \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
